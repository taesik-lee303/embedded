#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ëŒ€í™” ëª¨ë“œ ë””ìŠ¤í”Œë ˆì´
- display-control í† í”½ì„ êµ¬ë…í•˜ì—¬ ì¡°ê±´ì— ë”°ë¼ ëŒ€í™” í™”ë©´ìœ¼ë¡œ ì „í™˜
- MP4 ë¹„ë””ì˜¤ ì¬ìƒ ê¸°ëŠ¥ í¬í•¨
- ìŒì„± ëŒ€í™” ì‹œê°í™”
"""

import os
import re
import json
import time
import threading
import subprocess
from datetime import datetime
import sys
import math

# ëª¨ë‹ˆí„° ì¢Œí‘œ íƒìƒ‰
def find_monitor_offset(prefer_size=(480,480), fallback=(3840,0)):
    try:
        out = subprocess.run(["xrandr","--listmonitors"], capture_output=True, text=True, timeout=3)
        if out.returncode == 0:
            for line in out.stdout.splitlines():
                m = re.search(r"(\S+)\s+(\d+)/\d+x(\d+)/\d+\+(\d+)\+(\d+)", line)
                if m:
                    w,h,x,y = map(int,[m.group(2),m.group(3),m.group(4),m.group(5)])
                    if (w,h)==prefer_size: return (x,y)
    except Exception:
        pass
    try:
        out = subprocess.run(["xrandr","--query"], capture_output=True, text=True, timeout=3)
        if out.returncode == 0:
            for line in out.stdout.splitlines():
                m = re.search(r"^(\S+)\s+connected\s+(\d+)x(\d+)\+(\d+)\+(\d+)", line)
                if m:
                    w,h,x,y = map(int,[m.group(2),m.group(3),m.group(4),m.group(5)])
                    if (w,h)==prefer_size: return (x,y)
    except Exception:
        pass
    return fallback

pos = find_monitor_offset()
os.environ["SDL_VIDEO_WINDOW_POS"] = f"{pos[0]},{pos[1]}"

import pygame
import cv2

# ì¹´í”„ì¹´ ì„¤ì •
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))

# KafkaëŠ” ì„ íƒì  ì„í¬íŠ¸
KAFKA_ENABLED = True
try:
    from kafka import KafkaConsumer
    from core.kafka_config import setup_logging, get_logger, KAFKA_CONSUMER_CONFIG
except Exception as e:
    KAFKA_ENABLED = False
    print(f"âš ï¸ Kafka ì‚¬ìš© ë¶ˆê°€: {e}")

pygame.init()

# ì„¤ì •
SIZE = 480
CENTER = SIZE // 2
FPS = 30

# ìƒ‰ìƒ
COL_BG = (20, 25, 35)           # ì–´ë‘ìš´ ë°°ê²½
COL_PRIMARY = (100, 200, 255)   # ë©”ì¸ ì»¬ëŸ¬ (íŒŒë€ìƒ‰)
COL_ACCENT = (255, 150, 100)    # ì•¡ì„¼íŠ¸ ì»¬ëŸ¬ (ì£¼í™©ìƒ‰)
COL_TEXT = (255, 255, 255)      # í…ìŠ¤íŠ¸
COL_MUTED = (150, 150, 150)     # ë¹„í™œì„± í…ìŠ¤íŠ¸

screen = pygame.display.set_mode((SIZE, SIZE))
pygame.display.set_caption("AI Conversation Display")
clock = pygame.time.Clock()

# í°íŠ¸ ì„¤ì •
def get_korean_font():
    font_paths = [
        "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
        "/usr/share/fonts/truetype/noto/NotoSansKR-Regular.ttf",
        "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
    ]
    for path in font_paths:
        if os.path.exists(path):
            return path
    return None

FONT_PATH = get_korean_font()

def make_font(size, bold=False):
    if FONT_PATH:
        font = pygame.font.Font(FONT_PATH, size)
        if bold: font.set_bold(True)
        return font
    return pygame.font.SysFont("Arial", size, bold=bold)

font_large = make_font(24, True)
font_medium = make_font(18, False)
font_small = make_font(14, False)

class ConversationDisplay:
    def __init__(self):
        # ë¡œê¹… ì„¤ì •
        if KAFKA_ENABLED:
            setup_logging(log_file="conversation_display.log")
            self.logger = get_logger("ConversationDisplay")
        else:
            import logging
            logging.basicConfig(level=logging.INFO)
            self.logger = logging.getLogger("ConversationDisplay")
        
        # ì¹´í”„ì¹´ ì„¤ì •
        self.consumer = None
        self.kafka_thread = None
        self.is_running = True
        
        # ë””ìŠ¤í”Œë ˆì´ ìƒíƒœ
        self.current_mode = "waiting"  # waiting, conversation, video
        self.conversation_active = False
        self.video_playing = False
        
        # ëŒ€í™” ë°ì´í„°
        self.conversation_history = []
        self.current_user_text = ""
        self.current_ai_text = ""
        self.status_text = "ëŒ€í™” ëŒ€ê¸° ì¤‘..."
        
        # ë¹„ë””ì˜¤ ì¬ìƒ
        self.video_cap = None
        self.video_frame = None
        self.video_path = None
        
        # ì• ë‹ˆë©”ì´ì…˜
        self.pulse_animation = 0.0
        self.text_scroll_offset = 0
        
        # self.init_kafka()
    
    def init_kafka(self):
        """ì¹´í”„ì¹´ ì´ˆê¸°í™”"""
        global KAFKA_ENABLED
        if not KAFKA_ENABLED:
            self.logger.warning("Kafka ë¹„í™œì„±í™” - í…ŒìŠ¤íŠ¸ ëª¨ë“œë¡œ ì‹¤í–‰")
            return
        
        try:
            consumer_config = KAFKA_CONSUMER_CONFIG.copy()
            consumer_config['group_id'] = 'conversation-display-group'
            consumer_config['auto_offset_reset'] = 'latest'
            
            self.consumer = KafkaConsumer(
                "display-control",
                "audio-input",
                "audio-commands", 
                **consumer_config
            )
            
            self.kafka_thread = threading.Thread(target=self.kafka_consumer_loop)
            self.kafka_thread.daemon = True
            self.kafka_thread.start()
            
            self.logger.info("âœ… Kafka ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ Kafka ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            KAFKA_ENABLED = False
    
    def kafka_consumer_loop(self):
        """ì¹´í”„ì¹´ ë©”ì‹œì§€ ìˆ˜ì‹  ë£¨í”„"""
        for message in self.consumer:
            if not self.is_running:
                break
            
            try:
                topic = message.topic
                data = message.value
                
                self.logger.info(f"ğŸ“¨ ì¹´í”„ì¹´ ë©”ì‹œì§€ ìˆ˜ì‹ : {topic}")
                
                
                    
            except Exception as e:
                self.logger.error(f"âŒ ì¹´í”„ì¹´ ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    def handle_display_control(self, data):
        """ë””ìŠ¤í”Œë ˆì´ ì œì–´ ëª…ë ¹ ì²˜ë¦¬"""
        try:
            command = data.get("command", "")
            mode = data.get("mode", "")
            return_to_default = data.get("return_to_default", False)
            
            if command == "start_conversation":
                self.start_conversation_mode()
            elif command == "stop_conversation":
                self.stop_conversation_mode()
            elif command == "play_video":
                video_path = data.get("video_path", "")
                self.play_video(video_path)
            elif command == "stop_video":
                self.stop_video()
            elif mode == "conversation":
                self.current_mode = "conversation"
                self.conversation_active = True
                self.status_text = "ëŒ€í™” ëª¨ë“œ í™œì„±í™”"
            elif return_to_default:
                # ì„¼ì„œ ë””ìŠ¤í”Œë ˆì´ë¡œ ë³µê·€ ì‹ í˜¸ - ëŒ€í™” ë””ìŠ¤í”Œë ˆì´ ìˆ¨ê¹€
                self.current_mode = "waiting"
                self.conversation_active = False
                self.status_text = "ì„¼ì„œ ë””ìŠ¤í”Œë ˆì´ë¡œ ë³µê·€"
                self.logger.info("ğŸ“º ì„¼ì„œ ë””ìŠ¤í”Œë ˆì´ë¡œ ë³µê·€ - ëŒ€í™” í™”ë©´ ìˆ¨ê¹€")
                
            self.logger.info(f"ğŸ›ï¸ ë””ìŠ¤í”Œë ˆì´ ì œì–´: {data}")
            
        except Exception as e:
            self.logger.error(f"âŒ ë””ìŠ¤í”Œë ˆì´ ì œì–´ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    def handle_audio_input(self, data):
        """ì˜¤ë””ì˜¤ ì…ë ¥ ì²˜ë¦¬ (STT ê²°ê³¼)"""
        try:
            if data.get("action") == "stt_result":
                user_text = data.get("recognized_text", "")
                if user_text:
                    self.current_user_text = user_text
                    self.add_to_conversation("ì‚¬ìš©ì", user_text)
                    self.status_text = "AI ì‘ë‹µ ëŒ€ê¸° ì¤‘..."
                    
        except Exception as e:
            self.logger.error(f"âŒ ì˜¤ë””ì˜¤ ì…ë ¥ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    def handle_audio_commands(self, data):
        """ì˜¤ë””ì˜¤ ëª…ë ¹ ì²˜ë¦¬ (TTS ê²°ê³¼)"""
        try:
            if data.get("action") == "tts_result":
                ai_text = data.get("text", "")
                if ai_text:
                    self.current_ai_text = ai_text
                    self.add_to_conversation("AI", ai_text)
                    self.status_text = "ì‘ë‹µ ì™„ë£Œ"
                    
        except Exception as e:
            self.logger.error(f"âŒ ì˜¤ë””ì˜¤ ëª…ë ¹ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    def add_to_conversation(self, speaker, text):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€"""
        self.conversation_history.append({
            "speaker": speaker,
            "text": text,
            "timestamp": time.time()
        })
        
        # ìµœëŒ€ 10ê°œ ëŒ€í™”ë§Œ ìœ ì§€
        if len(self.conversation_history) > 10:
            self.conversation_history.pop(0)
    
    def start_conversation_mode(self):
        """ëŒ€í™” ëª¨ë“œ ì‹œì‘"""
        self.current_mode = "conversation"
        self.conversation_active = True
        self.status_text = "ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”"
        self.logger.info("ğŸ¤ ëŒ€í™” ëª¨ë“œ ì‹œì‘")
    
    def stop_conversation_mode(self):
        """ëŒ€í™” ëª¨ë“œ ì¢…ë£Œ"""
        self.current_mode = "waiting"
        self.conversation_active = False
        self.status_text = "ëŒ€í™” ì¢…ë£Œ"
        self.conversation_history.clear()
        self.logger.info("ğŸ›‘ ëŒ€í™” ëª¨ë“œ ì¢…ë£Œ")
    
    def play_video(self, video_path):
        """ë¹„ë””ì˜¤ ì¬ìƒ"""
        try:
            if not os.path.exists(video_path):
                self.logger.error(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ ì—†ìŒ: {video_path}")
                return
            
            self.video_path = video_path
            self.video_cap = cv2.VideoCapture(video_path)
            
            if not self.video_cap.isOpened():
                self.logger.error(f"âŒ ë¹„ë””ì˜¤ ì—´ê¸° ì‹¤íŒ¨: {video_path}")
                return
            
            self.video_playing = True
            self.current_mode = "video"
            self.logger.info(f"ğŸ¬ ë¹„ë””ì˜¤ ì¬ìƒ ì‹œì‘: {video_path}")
            
        except Exception as e:
            self.logger.error(f"âŒ ë¹„ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨: {e}")
    
    def stop_video(self):
        """ë¹„ë””ì˜¤ ì¬ìƒ ì¤‘ì§€"""
        if self.video_cap:
            self.video_cap.release()
            self.video_cap = None
        
        self.video_playing = False
        self.video_frame = None
        self.current_mode = "waiting"
        self.logger.info("â¹ï¸ ë¹„ë””ì˜¤ ì¬ìƒ ì¤‘ì§€")
    
    def update_video_frame(self):
        """ë¹„ë””ì˜¤ í”„ë ˆì„ ì—…ë°ì´íŠ¸"""
        if not self.video_playing or not self.video_cap:
            return
        
        ret, frame = self.video_cap.read()
        if ret:
            # OpenCV BGR -> RGB ë³€í™˜
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            # ì›í˜• ë””ìŠ¤í”Œë ˆì´ì— ë§ê²Œ ë¦¬ì‚¬ì´ì¦ˆ
            frame = cv2.resize(frame, (SIZE, SIZE))
            
            # NumPy array -> Pygame surface
            self.video_frame = pygame.surfarray.make_surface(frame.swapaxes(0, 1))
        else:
            # ë¹„ë””ì˜¤ ëë‚˜ë©´ ë£¨í”„ ë˜ëŠ” ì •ì§€
            self.video_cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # ë£¨í”„
    
    def draw_waiting_screen(self):
        """ëŒ€ê¸° í™”ë©´"""
        screen.fill(COL_BG)
        
        # ì¤‘ì•™ ì›í˜• í‘œì‹œ
        center = (CENTER, CENTER)
        radius = 80 + int(20 * abs(math.sin(self.pulse_animation)))
        pygame.draw.circle(screen, COL_PRIMARY, center, radius, 3)
        
        # íƒ€ì´í‹€
        title_surf = font_large.render("AI ëŒ€í™” ì‹œìŠ¤í…œ", True, COL_TEXT)
        title_rect = title_surf.get_rect(center=(CENTER, CENTER - 150))
        screen.blit(title_surf, title_rect)
        
        # ìƒíƒœ í…ìŠ¤íŠ¸
        status_surf = font_medium.render(self.status_text, True, COL_MUTED)
        status_rect = status_surf.get_rect(center=(CENTER, CENTER + 150))
        screen.blit(status_surf, status_rect)
        
        # ì‹œê°„
        now = datetime.now()
        time_surf = font_small.render(now.strftime("%H:%M:%S"), True, COL_MUTED)
        time_rect = time_surf.get_rect(center=(CENTER, SIZE - 30))
        screen.blit(time_surf, time_rect)
    
    def draw_conversation_screen(self):
        """ëŒ€í™” í™”ë©´"""
        screen.fill(COL_BG)
        
        # ìƒë‹¨ í—¤ë”
        header_surf = font_medium.render("ğŸ¤ AI ëŒ€í™” ì¤‘", True, COL_PRIMARY)
        header_rect = header_surf.get_rect(center=(CENTER, 30))
        screen.blit(header_surf, header_rect)
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬
        y_offset = 70
        for i, conv in enumerate(self.conversation_history[-5:]):  # ìµœê·¼ 5ê°œë§Œ í‘œì‹œ
            speaker_color = COL_ACCENT if conv["speaker"] == "ì‚¬ìš©ì" else COL_PRIMARY
            
            # ìŠ¤í”¼ì»¤ ë¼ë²¨
            speaker_surf = font_small.render(f"{conv['speaker']}:", True, speaker_color)
            screen.blit(speaker_surf, (20, y_offset))
            
            # í…ìŠ¤íŠ¸ (ê¸´ í…ìŠ¤íŠ¸ëŠ” ì¤„ë°”ê¿ˆ)
            text = conv["text"]
            words = text.split()
            lines = []
            current_line = ""
            
            for word in words:
                test_line = current_line + word + " "
                if font_small.size(test_line)[0] < SIZE - 40:
                    current_line = test_line
                else:
                    if current_line:
                        lines.append(current_line.strip())
                    current_line = word + " "
            
            if current_line:
                lines.append(current_line.strip())
            
            for line in lines[:2]:  # ìµœëŒ€ 2ì¤„ë§Œ
                text_surf = font_small.render(line, True, COL_TEXT)
                screen.blit(text_surf, (20, y_offset + 20))
                y_offset += 18
            
            y_offset += 25
        
        # í˜„ì¬ ìƒíƒœ
        if self.status_text:
            status_surf = font_small.render(self.status_text, True, COL_MUTED)
            status_rect = status_surf.get_rect(center=(CENTER, SIZE - 30))
            screen.blit(status_surf, status_rect)
    
    def draw_video_screen(self):
        """ë¹„ë””ì˜¤ í™”ë©´"""
        if self.video_frame:
            screen.blit(self.video_frame, (0, 0))
        else:
            screen.fill((0, 0, 0))
            
            # ë¹„ë””ì˜¤ ë¡œë”© í‘œì‹œ
            loading_surf = font_medium.render("ë¹„ë””ì˜¤ ë¡œë”© ì¤‘...", True, COL_TEXT)
            loading_rect = loading_surf.get_rect(center=(CENTER, CENTER))
            screen.blit(loading_surf, loading_rect)
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰ ë£¨í”„"""
        self.logger.info("ğŸš€ ëŒ€í™” ë””ìŠ¤í”Œë ˆì´ ì‹œì‘")
        
        running = True
        while running:
            dt = clock.tick(FPS) / 1000.0
            
            # ì´ë²¤íŠ¸ ì²˜ë¦¬
            for event in pygame.event.get():
                if event.type == pygame.QUIT:
                    running = False
                elif event.type == pygame.KEYDOWN:
                    if event.key == pygame.K_ESCAPE:
                        running = False
                    elif event.key == pygame.K_c:  # í…ŒìŠ¤íŠ¸ìš© ëŒ€í™” ì‹œì‘
                        self.start_conversation_mode()
                    elif event.key == pygame.K_v:  # í…ŒìŠ¤íŠ¸ìš© ë¹„ë””ì˜¤ ì¬ìƒ
                        test_video = "/path/to/test/video.mp4"  # ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½
                        if os.path.exists(test_video):
                            self.play_video(test_video)
            
            # ì• ë‹ˆë©”ì´ì…˜ ì—…ë°ì´íŠ¸
            self.pulse_animation += dt * 2
            
            # ë¹„ë””ì˜¤ í”„ë ˆì„ ì—…ë°ì´íŠ¸
            if self.current_mode == "video":
                self.update_video_frame()
            
            # í™”ë©´ ê·¸ë¦¬ê¸°
            if self.current_mode == "waiting":
                self.draw_waiting_screen()
            elif self.current_mode == "conversation":
                self.draw_conversation_screen()
            elif self.current_mode == "video":
                self.draw_video_screen()
            
            pygame.display.flip()
        
        self.cleanup()
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.is_running = False
        
        if self.video_cap:
            self.video_cap.release()
        
        if self.consumer:
            self.consumer.close()
        
        if self.kafka_thread:
            self.kafka_thread.join(timeout=5)
        
        pygame.quit()
        self.logger.info("ğŸ‘‹ ëŒ€í™” ë””ìŠ¤í”Œë ˆì´ ì¢…ë£Œ")

if __name__ == "__main__":
    display = ConversationDisplay()
    display.run()